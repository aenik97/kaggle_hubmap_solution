{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for collab\n",
    "# !pip install -q timm\n",
    "# !pip install -q scikit-image==0.19.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e880e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data here\n",
    "# https://www.kaggle.com/competitions/hubmap-organ-segmentation/data\n",
    "\n",
    "# pvt_v2_b4 weights can be downloded here\n",
    "# !wget -q https://github.com/whai362/PVT/releases/download/v2/pvt_v2_b4.pth -O ../pvt_v2_weights/pvt_v2_b4.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f39134",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pvt_v2_kaggle as pvt_v2\n",
    "import daformer\n",
    "import rle_format\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = '../input/hubmap-organ-segmentation'\n",
    "\n",
    "# FIX SEED\n",
    "seed = 442\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "from skimage.transform import rescale\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# plots\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "\n",
    "# treading\n",
    "N_JOBS = 0\n",
    "\n",
    "# model hyperparameters\n",
    "H = 704\n",
    "W = H\n",
    "\n",
    "\n",
    "# train - hpa data\n",
    "# public - hubmap data + hpa data\n",
    "# private - hubmap data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be588d",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b55182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'train.csv'))\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=seed, stratify=df['organ'])\n",
    "\n",
    "train_ids, val_ids = train_df['id'].values, val_df['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff4bea",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae192f24",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Rotate(\n",
    "        p=0.5,\n",
    "        value=1,\n",
    "        mask_value=0,\n",
    "    ),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=0.5),\n",
    "    ], p=0.5),\n",
    "    A.OneOf([\n",
    "        A.HueSaturationValue(10, 15, 10),\n",
    "        A.CLAHE(clip_limit=4),\n",
    "        A.RandomGamma(p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.5),            \n",
    "    ], p=0.5),      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048e7d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_normalize = A.Compose([\n",
    "    A.Resize(\n",
    "        height=H, \n",
    "        width=W,\n",
    "        p=1\n",
    "    ),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "mask_transform = A.Compose([\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a6dab",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hbmp_pix = {\n",
    "    'kidney': 0.5,\n",
    "    'largeintestine': 0.229,\n",
    "    'lung': 0.7562,\n",
    "    'spleen': 0.4945,\n",
    "    'prostate': 6.263\n",
    "}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        idxs,\n",
    "        main_transform,\n",
    "        resize_normalize,\n",
    "        mask_transform\n",
    "    ):\n",
    "        self.idxs = idxs\n",
    "        self.df = pd.read_csv(os.path.join(DATA_FOLDER, 'train.csv')).set_index('id').loc[self.idxs]\n",
    "\n",
    "        self.main_transform = main_transform\n",
    "        self.resize_normalize = resize_normalize\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.idxs[idx]\n",
    "        img_name = os.path.join(DATA_FOLDER, 'train_images', f'{idx}.tiff')\n",
    "\n",
    "        image = io.imread(img_name)\n",
    "        mask = rle_format.rle2mask(\n",
    "            self.df.loc[idx, 'rle'], \n",
    "            shape=image.shape[:2]\n",
    "        ) \n",
    "\n",
    "        scale = 0.4 / hbmp_pix[self.df.loc[idx, 'organ']]\n",
    "        image = (rescale(image, scale, order=1, anti_aliasing=True, channel_axis=2) * 255).astype(np.uint8)\n",
    "\n",
    "        transformed = self.main_transform(image=image, mask=mask)\n",
    "        sample = {\n",
    "            'pixel_values': self.resize_normalize(image=transformed['image'])['image'],\n",
    "            'labels': self.mask_transform(image=transformed['mask'])['image'].float()\n",
    "        }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54983c7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = CustomDataset(\n",
    "    idxs=val_ids,\n",
    "    main_transform=A.Compose([]), \n",
    "    resize_normalize=resize_normalize,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    idxs=train_ids,\n",
    "    main_transform=train_transform, \n",
    "    resize_normalize=resize_normalize,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VAL_BATCH_SIZE = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=N_JOBS)\n",
    "val_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False,  num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee49576",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbf9c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder =  daformer.daformer_conv3x3(\n",
    "            encoder_dim = [64, 128, 320, 512],\n",
    "            decoder_dim = 320,\n",
    "            dilation = None\n",
    "        )\n",
    "        \n",
    "        self.logit = nn.Sequential(\n",
    "            nn.Conv2d(320, 1, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)[0]\n",
    "        x = self.logit(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncDec(nn.Module):\n",
    "    def __init__(\n",
    "        self\n",
    "    ):\n",
    "        super(EncDec, self).__init__()\n",
    "        encoder=pvt_v2.pvt_v2_b4()\n",
    "        # pvt_v2_b4 weights can be downloded here\n",
    "        # https://github.com/whai362/PVT/releases/tag/v2\n",
    "        encoder.load_state_dict(torch.load('../pvt_v2_weights/pvt_v2_b4.pth'))\n",
    "        self.encoder = encoder\n",
    "        self.decoder = Decoder()\n",
    "        self.upsamle = nn.Upsample(\n",
    "            scale_factor=4,\n",
    "            mode='nearest'\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return self.upsamle(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69031f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class IoULoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU\n",
    "\n",
    "    \n",
    "def dice_metric(outputs, mask):\n",
    "    interpol_out = (F.interpolate(outputs, (mask.shape[-2], mask.shape[-1]))[0] > 0.5).int()\n",
    "    return (2 * (interpol_out * mask).sum() / (interpol_out.sum() +  mask.sum())).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64db83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "model = EncDec()\n",
    "\n",
    "model.to(device)\n",
    "loss_fn = IoULoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "NUM_ACCUMULATION_IMAGES = 16\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_losses_bce = []\n",
    "start_time = datetime.datetime.now()\n",
    "accum_im = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c69641",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # TRAIN\n",
    "    running_loss = []\n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, mask = data['pixel_values'], data['labels']\n",
    "        \n",
    "        outputs = model(inputs.to(device))\n",
    "        outputs = F.interpolate(outputs, mask.shape[-2:])\n",
    "        \n",
    "        batch_images = outputs.shape[0]\n",
    "        loss = loss_fn(\n",
    "            outputs,\n",
    "            mask.to(device)\n",
    "        )\n",
    "        loss = loss * batch_images / NUM_ACCUMULATION_IMAGES\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        accum_im += batch_images\n",
    "        if accum_im >= NUM_ACCUMULATION_IMAGES:\n",
    "            accum_im = 0\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss.append(loss.item())\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    scheduler.step()\n",
    "    train_losses.append(np.mean(running_loss))\n",
    "    \n",
    "    # VAL\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            inputs, mask = data['pixel_values'], data['labels']\n",
    "            outputs = model(inputs.to(device))\n",
    "            \n",
    "            val_loss += dice_metric(\n",
    "                torch.sigmoid(outputs),\n",
    "                mask.to(device)\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    val_losses.append(val_loss / len(val_ids))\n",
    "    \n",
    "    # SAVE BEST MODEL\n",
    "    if np.argmax(val_losses) == (len(val_losses) - 1):\n",
    "        path = os.path.join(\n",
    "            '..', 'model_checkpoints',\n",
    "            f'pvt_v2_b4_{epoch}_{H}_{loss_fn.__class__.__name__}_{val_losses[-1]}.pth'\n",
    "        )\n",
    "        torch.save(model.state_dict(), path)\n",
    "    \n",
    "    # OUTPUT / PLOT\n",
    "    clear_output()\n",
    "    print(datetime.datetime.now() - start_time, val_losses[-1], max(val_losses))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_img_input = io.imread(f'{DATA_FOLDER}/test_images/10078.tiff')\n",
    "        test_img = resize_normalize(image=test_img_input)['image'].unsqueeze(0).to(device)\n",
    "        test_img_out = torch.sigmoid(model(test_img)).cpu()[0][0]\n",
    "\n",
    "    plt.subplot(221)\n",
    "    plt.grid()\n",
    "    plt.plot(train_losses)\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.grid()\n",
    "    plt.plot(val_losses)\n",
    "\n",
    "    plt.subplot(223)\n",
    "    io.imshow(test_img_out.numpy())\n",
    "\n",
    "    plt.subplot(224)\n",
    "    io.imshow(test_img_input)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
